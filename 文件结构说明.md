# 项目文件结构说明

## 📁 目录结构总览

```
RLBoss/
├── 核心代码/                    # 核心算法实现
├── 测试代码/                    # 测试和实验脚本
├── 测试结果/                    # 实验输出结果
├── 文档/                        # 项目文档
└── 配置文件/                    # 配置和依赖
```

---

## 🔧 核心代码文件

### 1. `dual_policy_ppo.py` ⭐⭐⭐⭐⭐
**功能**: 双策略PPO算法的核心实现  
**重要性**: 最高  
**包含类**:
- `ActorCriticNetwork`: Actor-Critic神经网络
- `CuriosityModule`: 好奇心模块（前向-逆向动力学模型）
- `DualPolicyPPO`: 双策略PPO主类

**说明**: 这是整个项目的核心，实现了双策略PPO算法的所有关键组件。

---

### 2. `trainer.py` ⭐⭐⭐⭐
**功能**: 训练循环和环境交互管理  
**包含类**:
- `ReplayBuffer`: 经验回放缓冲区
- `Trainer`: 训练器主类（负责训练循环、评估、保存等）

**说明**: 负责管理训练过程，包括数据收集、策略更新、模型保存等。

---

### 3. `example_usage.py` ⭐⭐⭐⭐⭐
**功能**: 使用示例集合  
**说明**: 包含7个完整的使用示例，适合学习和参考。

---

### 4. `quick_start.py` ⭐⭐⭐⭐
**功能**: 快速入门脚本  
**说明**: 最简单的入门方式，可以快速运行一个演示实验。

---

### 5. `visualize_results.py` ⭐⭐⭐⭐
**功能**: 结果可视化工具  
**说明**: 用于分析和可视化训练结果。

---

## 🧪 测试代码文件

### ✅ 当前使用的测试代码

#### `sparse_reward_benchmark_v2.py` ⭐⭐⭐⭐⭐
**功能**: 稀疏奖励环境基准测试 V2（稳定性改进版）  
**输出目录**: `./sparse_test_v2/`  
**状态**: ✅ **当前符合模型环境要求的测试代码**

**特点**:
- 实现了稳定性改进的双策略PPO（Stable Dual PPO）
- 包含三种算法对比：Standard PPO、Dual PPO、Stable Dual PPO
- 针对稀疏奖励环境（MountainCar-v0）优化
- 自动生成三方对比图

**关键改进**:
1. 内在奖励系数自动衰减（从0.02衰减到0，600回合内）
2. KL散度系数降低10倍（0.0001 vs 0.001）
3. 禁用对手策略自动更新（保持训练目标稳定）
4. 降低熵正则化（0.01 vs 0.02）

**使用方法**:
```bash
python sparse_reward_benchmark_v2.py
```

---

### 📦 已归档的测试代码（位于 `used_test/` 文件夹）

以下测试代码已移动到 `used_test/` 文件夹，不再作为主要测试代码使用：

#### `sparse_reward_benchmark.py`
- **输出目录**: `./sparse_test/`
- **说明**: 早期版本的稀疏奖励测试代码

#### `final_benchmark.py`
- **输出目录**: `./final_test/`
- **说明**: 最终基准测试代码

#### `quick_benchmark.py`
- **输出目录**: `./quick_test/`
- **说明**: 快速基准测试代码

#### `simple_test.py`
- **输出目录**: `./simple_test/`
- **说明**: 简单测试代码

#### `smooth_dual_ppo_benchmark.py`
- **输出目录**: `./smooth_test/`
- **说明**: 平滑双策略PPO基准测试

#### `compare_experiments.py`
- **说明**: 对比实验脚本（双策略PPO vs 标准PPO vs PPO+Curiosity）

#### `experiment.py`
- **说明**: 单个实验脚本

#### `test_environments.py`
- **说明**: 多环境测试脚本

#### `run_all_tests.py`
- **说明**: 自动化测试套件

#### `超快速测试.py`
- **输出目录**: `./demo_test/`
- **说明**: 超快速演示测试

---

## 📊 测试结果文件夹

### `sparse_test_v2/` ⭐⭐⭐⭐⭐
**状态**: ✅ **当前使用的测试结果目录**  
**创建者**: `sparse_reward_benchmark_v2.py`  
**内容**:
- `MountainCar-v0_Standard_PPO/` - 标准PPO模型和结果
- `MountainCar-v0_Dual_PPO/` - 双策略PPO模型和结果
- `MountainCar-v0_Stable_Dual_PPO/` - 稳定双策略PPO模型和结果
- `three_way_comparison.png` - 三方对比图

**说明**: 这是当前符合模型环境要求的测试结果，包含三种算法的完整对比。

---

### 其他测试结果文件夹（历史数据）

以下文件夹包含历史测试结果，仅供参考：

- `sparse_test/` - 早期稀疏奖励测试结果
- `final_test/` - 最终基准测试结果
- `quick_test/` - 快速测试结果
- `simple_test/` - 简单测试结果
- `smooth_test/` - 平滑测试结果
- `improved_test/` - 改进测试结果

---

## 📖 文档文件

### 核心文档

- `README.md` ⭐⭐⭐⭐⭐ - 项目主文档，包含算法原理、使用方法等
- `ARCHITECTURE.md` ⭐⭐⭐⭐ - 系统架构详解
- `文件说明.md` ⭐⭐⭐ - 所有文件的详细说明
- `项目概览.md` ⭐⭐⭐⭐ - 项目全景介绍
- `快速安装指南.md` ⭐⭐⭐⭐⭐ - 详细的安装步骤
- `CHANGELOG.md` ⭐⭐ - 版本更新记录

### 问题诊断文档

- `修复总结.md` - 问题修复总结
- `问题诊断报告.md` - 问题诊断报告

---

## ⚙️ 配置文件

- `config.yaml` ⭐⭐⭐ - 配置文件，包含默认超参数设置
- `requirements.txt` ⭐⭐⭐⭐⭐ - Python依赖包列表
- `LICENSE` ⭐⭐ - MIT开源许可证

---

## 🎯 文件使用指南

### 快速开始
1. 阅读 `快速安装指南.md` 安装环境
2. 运行 `python quick_start.py` 进行快速演示
3. 阅读 `README.md` 了解算法原理

### 运行测试
1. **当前推荐**: 运行 `python sparse_reward_benchmark_v2.py`
   - 输出结果保存在 `sparse_test_v2/` 文件夹
   - 这是符合模型环境要求的测试代码

2. 学习示例: 运行 `python example_usage.py`

### 查看结果
- 主要测试结果: 查看 `sparse_test_v2/` 文件夹
- 可视化: 使用 `visualize_results.py` 分析结果

### 深入理解
1. 阅读 `ARCHITECTURE.md` 理解系统架构
2. 阅读 `dual_policy_ppo.py` 源码理解算法实现
3. 阅读 `trainer.py` 理解训练流程

---

## 📋 文件分类总结

### 核心代码（必须保留）
- `dual_policy_ppo.py` - 核心算法
- `trainer.py` - 训练器
- `example_usage.py` - 使用示例
- `quick_start.py` - 快速开始

### 当前测试代码（主要使用）
- `sparse_reward_benchmark_v2.py` ⭐ - 当前符合要求的测试代码

### 已归档测试代码（已移动到 `used_test/`）
- 所有其他测试脚本已移动到 `used_test/` 文件夹

### 测试结果（主要关注）
- `sparse_test_v2/` ⭐ - 当前测试结果目录

### 文档（重要参考）
- `README.md` - 主文档
- `ARCHITECTURE.md` - 架构文档
- `快速安装指南.md` - 安装指南

---

## 🔍 快速查找

**想要...**

- **运行测试** → `sparse_reward_benchmark_v2.py`
- **查看结果** → `sparse_test_v2/` 文件夹
- **学习算法** → `README.md` + `dual_policy_ppo.py`
- **快速开始** → `quick_start.py`
- **查看示例** → `example_usage.py`
- **历史测试代码** → `used_test/` 文件夹

---

## ⚠️ 重要提示

1. **当前测试代码**: `sparse_reward_benchmark_v2.py` 是唯一符合模型环境要求的测试代码
2. **测试结果**: `sparse_test_v2/` 是当前使用的测试结果目录
3. **历史代码**: 其他测试代码已移动到 `used_test/` 文件夹，仅供参考
4. **核心代码**: `dual_policy_ppo.py` 和 `trainer.py` 是核心，不要随意修改

---

<div align="center">

**最后更新**: 2025年  
**当前版本**: 使用 `sparse_reward_benchmark_v2.py` 作为主要测试代码

</div>



